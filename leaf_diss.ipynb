{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout,GlobalAveragePooling2D,AveragePooling2D,MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "import streamlit as st\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/home/vignesh/tomato_data/train'\n",
    "test_dir = '/home/vignesh/tomato_data/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751801264.256154    4912 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1722 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    image_size=(256, 256),\n",
    "    batch_size=32)\n",
    "\n",
    "train_data = train_data.map(lambda x, y: (x / 255.0, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    image_size=(256, 256),\n",
    "    batch_size=32)\n",
    "\n",
    "val_data = val_data.map(lambda x, y: (x / 255.0, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = DenseNet121(\n",
    "    weights='imagenet',\n",
    "    include_top = False,\n",
    "    input_shape=(256,256,3),\n",
    "    pooling='avg'\n",
    ")\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751796995.070491     863 service.cc:152] XLA service 0x7993ec003f80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1751796995.070528     863 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-07-06 10:16:35.423405: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1751796997.232892     863 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:08:57\u001b[0m 25s/step - accuracy: 0.0312 - loss: 3.0391"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751797012.354546     863 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 157ms/step - accuracy: 0.3646 - loss: 1.9286 - val_accuracy: 0.7460 - val_loss: 0.9393\n",
      "Epoch 2/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.7581 - loss: 0.7851 - val_accuracy: 0.8330 - val_loss: 0.5399\n",
      "Epoch 3/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.8343 - loss: 0.5289 - val_accuracy: 0.8670 - val_loss: 0.4098\n",
      "Epoch 4/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.8754 - loss: 0.4017 - val_accuracy: 0.8860 - val_loss: 0.3435\n",
      "Epoch 5/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.9022 - loss: 0.3274 - val_accuracy: 0.9010 - val_loss: 0.2966\n",
      "Epoch 6/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.9122 - loss: 0.2782 - val_accuracy: 0.9110 - val_loss: 0.2659\n",
      "Epoch 7/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 66ms/step - accuracy: 0.9265 - loss: 0.2365 - val_accuracy: 0.9130 - val_loss: 0.2420\n",
      "Epoch 8/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 62ms/step - accuracy: 0.9378 - loss: 0.2031 - val_accuracy: 0.9170 - val_loss: 0.2250\n",
      "Epoch 9/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 62ms/step - accuracy: 0.9460 - loss: 0.1755 - val_accuracy: 0.9260 - val_loss: 0.2127\n",
      "Epoch 10/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.9489 - loss: 0.1602 - val_accuracy: 0.9290 - val_loss: 0.2064\n",
      "Epoch 11/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.9578 - loss: 0.1422 - val_accuracy: 0.9320 - val_loss: 0.1926\n",
      "Epoch 12/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.9635 - loss: 0.1278 - val_accuracy: 0.9360 - val_loss: 0.1828\n",
      "Epoch 13/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 61ms/step - accuracy: 0.9600 - loss: 0.1184 - val_accuracy: 0.9380 - val_loss: 0.1799\n",
      "Epoch 14/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.9626 - loss: 0.1121 - val_accuracy: 0.9420 - val_loss: 0.1701\n",
      "Epoch 15/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step - accuracy: 0.9663 - loss: 0.0999 - val_accuracy: 0.9450 - val_loss: 0.1682\n",
      "Epoch 16/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.9707 - loss: 0.0917 - val_accuracy: 0.9490 - val_loss: 0.1585\n",
      "Epoch 17/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 59ms/step - accuracy: 0.9763 - loss: 0.0802 - val_accuracy: 0.9450 - val_loss: 0.1549\n",
      "Epoch 18/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.9779 - loss: 0.0777 - val_accuracy: 0.9460 - val_loss: 0.1542\n",
      "Epoch 19/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 61ms/step - accuracy: 0.9778 - loss: 0.0717 - val_accuracy: 0.9450 - val_loss: 0.1522\n",
      "Epoch 20/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.9761 - loss: 0.0713 - val_accuracy: 0.9520 - val_loss: 0.1452\n",
      "Epoch 21/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 62ms/step - accuracy: 0.9781 - loss: 0.0671 - val_accuracy: 0.9530 - val_loss: 0.1436\n",
      "Epoch 22/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.9821 - loss: 0.0564 - val_accuracy: 0.9540 - val_loss: 0.1428\n",
      "Epoch 23/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.9828 - loss: 0.0554 - val_accuracy: 0.9520 - val_loss: 0.1445\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, epochs=100, validation_data=val_data, callbacks=[EarlyStopping(patience=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.9471 - loss: 0.1521\n",
      "Validation Loss: 0.14453433454036713\n",
      "Validation Accuracy: 0.9520000219345093\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation data\n",
    "evaluation = model.evaluate(val_data)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Validation Loss:\", evaluation[0])\n",
    "print(\"Validation Accuracy:\", evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('leaf_disease_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open('leaf_disease_model_architecture.json', 'w') as f:\n",
    "    f.write(model_json)\n",
    "model.save_weights('leaf_disease_model.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('leaf_disease_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 11:00:15.103523: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-06 11:00:15.191475: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751799615.224736   10754 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751799615.235534   10754 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751799615.290402   10754 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751799615.290445   10754 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751799615.290448   10754 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751799615.290449   10754 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-06 11:00:15.306195: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1751799619.367407   10754 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "TensorBoard logs will be saved to: ./logs/model_analysis/20250706-110022\n",
      "\n",
      "To start TensorBoard, run in terminal:\n",
      "tensorboard --logdir=./logs/model_analysis/20250706-110022\n",
      "\n",
      "Then open http://localhost:6006 in your browser\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Load saved model\n",
    "loaded_model = tf.keras.models.load_model('leaf_disease_model.h5')\n",
    "\n",
    "# Create a new log directory for TensorBoard\n",
    "log_dir = './logs/model_analysis/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create TensorBoard callback for model analysis\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    update_freq='epoch'\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9065d1b3d39e1d36\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9065d1b3d39e1d36\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./logs/model_analysis/val_eval_20250706-110721"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751800011.066753   11953 service.cc:152] XLA service 0x78a414002350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1751800011.067079   11953 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-07-06 11:06:51.273350: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1751800014.924390   11953 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:29\u001b[0m 22s/step - accuracy: 0.9062 - loss: 0.2125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751800029.449223   11953 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 393ms/step - accuracy: 0.9548 - loss: 0.1295\n",
      "Validation Loss: 0.1444859504699707\n",
      "Validation Accuracy: 0.9520000219345093\n",
      "Validation metrics logged to: ./logs/model_analysis/val_eval_20250706-110721\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('leaf_disease_model.h5')\n",
    "\n",
    "# Evaluate on validation data\n",
    "val_evaluation = loaded_model.evaluate(val_data)\n",
    "val_loss, val_accuracy = val_evaluation[0], val_evaluation[1]\n",
    "\n",
    "# Log validation metrics to TensorBoard\n",
    "import datetime\n",
    "val_log_dir = './logs/model_analysis/val_eval_' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "val_summary_writer = tf.summary.create_file_writer(val_log_dir)\n",
    "with val_summary_writer.as_default():\n",
    "    tf.summary.scalar('val_loss', val_loss, step=0)\n",
    "    tf.summary.scalar('val_accuracy', val_accuracy, step=0)\n",
    "\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation metrics logged to: {val_log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "st.title('Leaf Disease Model: Upload and Predict')\n",
    "\n",
    "uploaded_file = st.file_uploader('Choose an image...', type=['jpg', 'jpeg', 'png'])\n",
    "if uploaded_file is not None:\n",
    "    image = Image.open(uploaded_file).convert('RGB')\n",
    "    st.image(image, caption='Uploaded Image', use_column_width=True)\n",
    "    st.write(\"\")\n",
    "\n",
    "    # Preprocess the image\n",
    "    img = image.resize((256, 256))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    prediction = loaded_model.predict(img_array)\n",
    "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "\n",
    "    st.write(f'Predicted class: {predicted_class}')\n",
    "    st.write(f'Prediction probabilities: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m class_names = \u001b[43mtrain_data\u001b[49m.class_names\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(class_names)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "class_names = train_data.class_names\n",
    "print(class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfwk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
